{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccastelblancob/Metodos_Comptacion_Estadistica/blob/Tareas/computacion_tarea_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8JB66c2U7eE",
        "outputId": "d332068c-9061-4f99-d0dd-cabbd4979a4f"
      },
      "id": "K8JB66c2U7eE",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "874c6b04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "874c6b04",
        "outputId": "3ad81151-ad0c-4ee2-8b67-efcdc22a4075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo LDA"
      ],
      "metadata": {
        "id": "8RdeZR6vmWka"
      },
      "id": "8RdeZR6vmWka"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc553c75",
      "metadata": {
        "id": "bc553c75"
      },
      "outputs": [],
      "source": [
        "# Solo se va a lematizar.\n",
        "def lemmatize_stemming(text):\n",
        "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text): #  gensim.utils.simple_preprocess tokeniza el texto\n",
        "        # Se eliminan las palabras vacias.\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) >3 or token == \"no\":\n",
        "            result.append(lemmatize_stemming(token))\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "165cd629",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "165cd629",
        "outputId": "f9a12b39-3429-4e89-e482-f4e7a1beb952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-0bac8b4183cb>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_text[\"index\"] = data_text.index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3063"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/drive/MyDrive/IA-2023-2/tweets.csv')\n",
        "data_text = data[[\"tweet\"]]\n",
        "data_text[\"index\"] = data_text.index\n",
        "documents = data_text\n",
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbd7d879",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbd7d879",
        "outputId": "9772c138-8cfa-4ea0-82d8-a599ee17491d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "documento original: \n",
            "['', 'no', 'me', 'siento', 'bien', 'pero', 'me', 'gusta', 'en', 'el', 'buen', 'sentido', 'si', 'eso', 'tiene', 'sentido']\n",
            "\n",
            "\n",
            " documento tokenizado y lematizado: \n",
            "['no', 'siento', 'bien', 'pero', 'gusta', 'buen', 'sentido', 'tiene', 'sentido']\n"
          ]
        }
      ],
      "source": [
        "doc_sample = documents[documents['index'] == 3025].values[0][0]\n",
        "print('documento original: ')\n",
        "words = []\n",
        "for word in doc_sample.split(' '):\n",
        "    words.append(word)\n",
        "print(words)\n",
        "print('\\n\\n documento tokenizado y lematizado: ')\n",
        "print(preprocess(doc_sample))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e79bfd06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e79bfd06",
        "outputId": "44985ec5-9b37-429f-ac2c-a464baae1769"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [verdadera, razón, estás, triste, apegas, pers...\n",
              "1           [mayor, problema, pensar, demasiado, todo]\n",
              "2        [peor, tristeza, tristeza, enseñes, esconder]\n",
              "3    [no, puedo, hacerte, entender, no, puedo, hace...\n",
              "4    [no, creo, nadie, realmente, entienda, cansado...\n",
              "5    [peor, sensación, cuando, algo, mata, dentro, ...\n",
              "6    [cuando, estoy, herido, cierro, convierto, per...\n",
              "7    [pensar, demasiado, arruinar, arruinar, situac...\n",
              "8    [estoy, decepcionado, mismo, porque, mejor, el...\n",
              "9    [estoy, cansada, esto, cuerpo, está, cansada, ...\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#la función map toma cada fila de documents['tweet'] y la pasa por la función preprocess\n",
        "processed_docs = documents['tweet'].map(preprocess)\n",
        "processed_docs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7518a35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7518a35",
        "outputId": "898f1261-1946-463f-9404-49d2db348f35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 apegas\n",
            "1 atención\n",
            "2 cuando\n",
            "3 dejaras\n",
            "4 demasiado\n",
            "5 distanciado\n",
            "6 están\n",
            "7 estás\n",
            "8 gente\n",
            "9 haces\n",
            "10 ignoran\n"
          ]
        }
      ],
      "source": [
        "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "633927bf",
      "metadata": {
        "id": "633927bf"
      },
      "outputs": [],
      "source": [
        "#no_below: especifica el número mínimo de documentos en los que debe aparecer una palabra para que se mantenga en el diccionario\n",
        "#no_above: especifica la proporción máxima de documentos en los que una palabra puede aparecer para que se mantenga en el diccionario.\n",
        "#keep_n: controla el número total máximo de palabras que se mantendrán en el diccionario después del proceso de filtrado.\n",
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c554add",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c554add",
        "outputId": "edecae36-f36d-4b93-c59a-f60733ceaf41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(18, 1), (22, 1), (64, 1), (103, 2), (107, 1), (152, 1), (189, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Se crea una bolsa de palabras\n",
        "# Primera enntrada: Identificador único de la palabra. Segunda entrada: Frecuencia de la palabra.\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "bow_corpus[3025]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "968e6ec2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "968e6ec2",
        "outputId": "df06764d-3126-4a3b-eec3-dc520d4f5f1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 18 (\"no\") aparece 1 una vez.\n",
            "Word 22 (\"bien\") aparece 1 una vez.\n",
            "Word 64 (\"siento\") aparece 1 una vez.\n",
            "Word 103 (\"sentido\") aparece 2 una vez.\n",
            "Word 107 (\"pero\") aparece 1 una vez.\n",
            "Word 152 (\"gusta\") aparece 1 una vez.\n",
            "Word 189 (\"tiene\") aparece 1 una vez.\n"
          ]
        }
      ],
      "source": [
        "bow_doc_15 = bow_corpus[3025]\n",
        "for i in range(len(bow_doc_15)):\n",
        "    print(\"Word {} (\\\"{}\\\") aparece {} una vez.\".format(bow_doc_15[i][0],\n",
        "                                               dictionary[bow_doc_15[i][0]],\n",
        "bow_doc_15[i][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4d0546a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4d0546a",
        "outputId": "6c75e9f3-0eea-40c7-f705-7345e58a77ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0.1253782036951276),\n",
            " (1, 0.38436155419005563),\n",
            " (2, 0.21108741411643359),\n",
            " (3, 0.16634826356371224),\n",
            " (4, 0.2234113770703681),\n",
            " (5, 0.22839805829516904),\n",
            " (6, 0.7280941313765652),\n",
            " (7, 0.2342823743667716),\n",
            " (8, 0.19527570849762166),\n",
            " (9, 0.19772871986412627)]\n"
          ]
        }
      ],
      "source": [
        "from gensim import corpora, models\n",
        "tfidf = models.TfidfModel(bow_corpus)\n",
        "corpus_tfidf = tfidf[bow_corpus]\n",
        "from pprint import pprint\n",
        "for doc in corpus_tfidf:\n",
        "    pprint(doc)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "619d155b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "619d155b",
        "outputId": "122a5926-357e-4ddd-84bb-1d479802df4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        }
      ],
      "source": [
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=5, id2word=dictionary, passes=2, workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "768b93bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "768b93bc",
        "outputId": "55ad6874-8c1d-4b09-c1e8-388c3a258b8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.171*\"no\" + 0.033*\"para\" + 0.032*\"alguien\" + 0.026*\"puedo\" + 0.022*\"nunca\" + 0.020*\"bien\" + 0.019*\"porque\" + 0.015*\"solo\" + 0.014*\"simplemente\" + 0.014*\"todo\"\n",
            "Topic: 1 \n",
            "Words: 0.075*\"no\" + 0.044*\"pero\" + 0.037*\"como\" + 0.032*\"solo\" + 0.030*\"para\" + 0.026*\"vida\" + 0.019*\"cuando\" + 0.018*\"porque\" + 0.018*\"siempre\" + 0.018*\"personas\"\n",
            "Topic: 2 \n",
            "Words: 0.062*\"no\" + 0.047*\"quiero\" + 0.042*\"todo\" + 0.034*\"estar\" + 0.031*\"solo\" + 0.026*\"para\" + 0.023*\"mierda\" + 0.023*\"cuando\" + 0.022*\"cansado\" + 0.020*\"puedo\"\n",
            "Topic: 3 \n",
            "Words: 0.055*\"no\" + 0.044*\"cuando\" + 0.038*\"todos\" + 0.036*\"siento\" + 0.034*\"estoy\" + 0.031*\"pero\" + 0.023*\"todo\" + 0.021*\"como\" + 0.020*\"siempre\" + 0.019*\"gente\"\n",
            "Topic: 4 \n",
            "Words: 0.084*\"no\" + 0.049*\"nadie\" + 0.036*\"para\" + 0.034*\"solo\" + 0.026*\"pero\" + 0.022*\"alguien\" + 0.021*\"cuando\" + 0.021*\"estoy\" + 0.018*\"mismo\" + 0.017*\"persona\"\n"
          ]
        }
      ],
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa7e629d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa7e629d",
        "outputId": "8d2209e1-0d77-45ae-890c-4d0155c3a7f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 Word: 0.069*\"no\" + 0.044*\"todos\" + 0.027*\"pero\" + 0.026*\"mierda\" + 0.025*\"estar\" + 0.024*\"como\" + 0.021*\"solo\" + 0.021*\"alguien\" + 0.020*\"seré\" + 0.020*\"bien\"\n",
            "Topic: 1 Word: 0.034*\"todo\" + 0.031*\"no\" + 0.029*\"para\" + 0.027*\"cuando\" + 0.024*\"como\" + 0.023*\"importa\" + 0.022*\"siempre\" + 0.019*\"hacer\" + 0.018*\"quiero\" + 0.016*\"porque\"\n",
            "Topic: 2 Word: 0.031*\"para\" + 0.027*\"no\" + 0.024*\"tengo\" + 0.022*\"nada\" + 0.018*\"nunca\" + 0.017*\"cada\" + 0.016*\"pensamientos\" + 0.016*\"amigos\" + 0.016*\"también\" + 0.016*\"realmente\"\n",
            "Topic: 3 Word: 0.034*\"vida\" + 0.030*\"no\" + 0.028*\"quiero\" + 0.020*\"nadie\" + 0.020*\"vivir\" + 0.018*\"solo\" + 0.016*\"estaré\" + 0.016*\"siempre\" + 0.015*\"mejor\" + 0.015*\"alguien\"\n",
            "Topic: 4 Word: 0.047*\"estoy\" + 0.041*\"solo\" + 0.037*\"no\" + 0.023*\"mismo\" + 0.023*\"puedo\" + 0.020*\"cosas\" + 0.020*\"dolor\" + 0.018*\"personas\" + 0.018*\"esto\" + 0.018*\"cuando\"\n"
          ]
        }
      ],
      "source": [
        "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=5, id2word=dictionary, passes=2, workers=2)\n",
        "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
        "    print('Topic: {} Word: {}'.format(idx, topic))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a7655a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a7655a6",
        "outputId": "164f2cde-499b-4d92-fa27-bed8f88c3eda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['no',\n",
              " 'siento',\n",
              " 'bien',\n",
              " 'pero',\n",
              " 'gusta',\n",
              " 'buen',\n",
              " 'sentido',\n",
              " 'tiene',\n",
              " 'sentido']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "processed_docs[3025]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce8ab55f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce8ab55f",
        "outputId": "6637bb96-fff3-417c-b664-aabc56426fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Score: 0.908891499042511\t \n",
            "Topic: 0.084*\"no\" + 0.049*\"nadie\" + 0.036*\"para\" + 0.034*\"solo\" + 0.026*\"pero\" + 0.022*\"alguien\" + 0.021*\"cuando\" + 0.021*\"estoy\" + 0.018*\"mismo\" + 0.017*\"persona\"\n",
            "\n",
            "Score: 0.022902699187397957\t \n",
            "Topic: 0.055*\"no\" + 0.044*\"cuando\" + 0.038*\"todos\" + 0.036*\"siento\" + 0.034*\"estoy\" + 0.031*\"pero\" + 0.023*\"todo\" + 0.021*\"como\" + 0.020*\"siempre\" + 0.019*\"gente\"\n",
            "\n",
            "Score: 0.022746924310922623\t \n",
            "Topic: 0.171*\"no\" + 0.033*\"para\" + 0.032*\"alguien\" + 0.026*\"puedo\" + 0.022*\"nunca\" + 0.020*\"bien\" + 0.019*\"porque\" + 0.015*\"solo\" + 0.014*\"simplemente\" + 0.014*\"todo\"\n",
            "\n",
            "Score: 0.02273695170879364\t \n",
            "Topic: 0.062*\"no\" + 0.047*\"quiero\" + 0.042*\"todo\" + 0.034*\"estar\" + 0.031*\"solo\" + 0.026*\"para\" + 0.023*\"mierda\" + 0.023*\"cuando\" + 0.022*\"cansado\" + 0.020*\"puedo\"\n",
            "\n",
            "Score: 0.022721877321600914\t \n",
            "Topic: 0.075*\"no\" + 0.044*\"pero\" + 0.037*\"como\" + 0.032*\"solo\" + 0.030*\"para\" + 0.026*\"vida\" + 0.019*\"cuando\" + 0.018*\"porque\" + 0.018*\"siempre\" + 0.018*\"personas\"\n"
          ]
        }
      ],
      "source": [
        "for index, score in sorted(lda_model[bow_corpus[3025]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f0272e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f0272e1",
        "outputId": "93df3487-ee82-4cb6-a7bd-38172c8c5ce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Score: 0.6417878866195679\t Topic: 0.069*\"no\" + 0.044*\"todos\" + 0.027*\"pero\" + 0.026*\"mierda\" + 0.025*\"estar\" + 0.024*\"como\" + 0.021*\"solo\" + 0.021*\"alguien\" + 0.020*\"seré\" + 0.020*\"bien\"\n",
            "\n",
            "Score: 0.2897302806377411\t Topic: 0.034*\"todo\" + 0.031*\"no\" + 0.029*\"para\" + 0.027*\"cuando\" + 0.024*\"como\" + 0.023*\"importa\" + 0.022*\"siempre\" + 0.019*\"hacer\" + 0.018*\"quiero\" + 0.016*\"porque\"\n",
            "\n",
            "Score: 0.02315969206392765\t Topic: 0.034*\"vida\" + 0.030*\"no\" + 0.028*\"quiero\" + 0.020*\"nadie\" + 0.020*\"vivir\" + 0.018*\"solo\" + 0.016*\"estaré\" + 0.016*\"siempre\" + 0.015*\"mejor\" + 0.015*\"alguien\"\n",
            "\n",
            "Score: 0.022766081616282463\t Topic: 0.031*\"para\" + 0.027*\"no\" + 0.024*\"tengo\" + 0.022*\"nada\" + 0.018*\"nunca\" + 0.017*\"cada\" + 0.016*\"pensamientos\" + 0.016*\"amigos\" + 0.016*\"también\" + 0.016*\"realmente\"\n",
            "\n",
            "Score: 0.022556038573384285\t Topic: 0.047*\"estoy\" + 0.041*\"solo\" + 0.037*\"no\" + 0.023*\"mismo\" + 0.023*\"puedo\" + 0.020*\"cosas\" + 0.020*\"dolor\" + 0.018*\"personas\" + 0.018*\"esto\" + 0.018*\"cuando\"\n"
          ]
        }
      ],
      "source": [
        "for index, score in sorted(lda_model_tfidf[bow_corpus[3025]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t Topic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3901a82b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3901a82b",
        "outputId": "dfde641d-a076-4c93-f367-7b65896f447f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.7950260639190674\t Topic: 0.084*\"no\" + 0.049*\"nadie\" + 0.036*\"para\" + 0.034*\"solo\" + 0.026*\"pero\"\n",
            "Score: 0.05227319151163101\t Topic: 0.171*\"no\" + 0.033*\"para\" + 0.032*\"alguien\" + 0.026*\"puedo\" + 0.022*\"nunca\"\n",
            "Score: 0.05127741023898125\t Topic: 0.075*\"no\" + 0.044*\"pero\" + 0.037*\"como\" + 0.032*\"solo\" + 0.030*\"para\"\n",
            "Score: 0.05076996982097626\t Topic: 0.055*\"no\" + 0.044*\"cuando\" + 0.038*\"todos\" + 0.036*\"siento\" + 0.034*\"estoy\"\n",
            "Score: 0.05065333470702171\t Topic: 0.062*\"no\" + 0.047*\"quiero\" + 0.042*\"todo\" + 0.034*\"estar\" + 0.031*\"solo\"\n"
          ]
        }
      ],
      "source": [
        "unseen_document = 'No entiendo que hace esto, ayuda'\n",
        "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
        "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45e1e673",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45e1e673",
        "outputId": "b14fcb50-b148-41a8-87e5-a76f36337a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.7969995737075806\t Topic: 0.084*\"no\" + 0.049*\"nadie\" + 0.036*\"para\" + 0.034*\"solo\" + 0.026*\"pero\"\n",
            "Score: 0.051063649356365204\t Topic: 0.171*\"no\" + 0.033*\"para\" + 0.032*\"alguien\" + 0.026*\"puedo\" + 0.022*\"nunca\"\n",
            "Score: 0.050672899931669235\t Topic: 0.075*\"no\" + 0.044*\"pero\" + 0.037*\"como\" + 0.032*\"solo\" + 0.030*\"para\"\n",
            "Score: 0.050639934837818146\t Topic: 0.062*\"no\" + 0.047*\"quiero\" + 0.042*\"todo\" + 0.034*\"estar\" + 0.031*\"solo\"\n",
            "Score: 0.050623971968889236\t Topic: 0.055*\"no\" + 0.044*\"cuando\" + 0.038*\"todos\" + 0.036*\"siento\" + 0.034*\"estoy\"\n"
          ]
        }
      ],
      "source": [
        "unseen_document = 'No entiendo que hace esto, ayuda'\n",
        "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
        "for index, score in sorted(lda_model_tfidf[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo SVD"
      ],
      "metadata": {
        "id": "TyTZ6WWmmrsu"
      },
      "id": "TyTZ6WWmmrsu"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0f52766c",
      "metadata": {
        "id": "0f52766c"
      },
      "outputs": [],
      "source": [
        "import re, string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initial_clean(text):\n",
        "    \"\"\"\n",
        "    Función para limpiar texto de sitios web, direcciones de correo electrónico y cualquier puntuación.\n",
        "    \"\"\"\n",
        "    text = text.lower() # lower case the text\n",
        "    text = nltk.word_tokenize(text)\n",
        "    return text\n",
        "\n",
        "stopwords_corpus = nltk.corpus.stopwords\n",
        "spa_stop_words = stopwords_corpus.words('spanish')\n",
        "stopset = spa_stop_words + list(string.punctuation)\n",
        "def remove_stop_words(text):\n",
        "    \"\"\"\n",
        "    Función que remueve las palabras vacías del texto\n",
        "    \"\"\"\n",
        "    return [word for word in text if word not in stopset]\n",
        "\n",
        "def apply_all(text):\n",
        "    \"\"\"\n",
        "    Función para aplicar todas las funciones anteriores\n",
        "    \"\"\"\n",
        "    words = remove_stop_words(initial_clean(text))\n",
        "    return \" \".join([i for i in words])"
      ],
      "metadata": {
        "id": "a2MCAXc5m36H"
      },
      "id": "a2MCAXc5m36H",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"processed_docs_1\"] = data[\"tweet\"].apply(lambda x: apply_all(x))\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.85, max_features=100)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(data[\"processed_docs_1\"])"
      ],
      "metadata": {
        "id": "4zY1TQbZnUNL"
      },
      "id": "4zY1TQbZnUNL",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar la descomposición SVD\n",
        "num_topics = 10  # Número de tópicos a extraer\n",
        "svd = TruncatedSVD(n_components=num_topics)\n",
        "svd_matrix = svd.fit_transform(tfidf_matrix)"
      ],
      "metadata": {
        "id": "5B6aTn36nqnD"
      },
      "id": "5B6aTn36nqnD",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "terms = tfidf_vectorizer.get_feature_names_out()\n",
        "for i, topic in enumerate(svd.components_):\n",
        "    top_terms_idx = topic.argsort()[::-1][:10]  # Mostrar las 10 palabras principales por tópico\n",
        "    top_terms = [terms[idx] for idx in top_terms_idx]\n",
        "    print(f'Tópico {i + 1}: {\" \".join(top_terms)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Eix2Mg9nxWk",
        "outputId": "e5b5cad0-6aa0-44e2-f210-806eab29e3f9"
      },
      "id": "3Eix2Mg9nxWk",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tópico 1: solo quiero si ser bien alguien siento tan nadie siempre\n",
            "Tópico 2: solo quiero morir aquí realidad vivo oh amigos dormir sentir\n",
            "Tópico 3: ser tan puedo siento quiero nunca feliz persona vida hacer\n",
            "Tópico 4: bien ser veces hacer puedo feliz cosas decir momento sonrisa\n",
            "Tópico 5: nadie importa bien siempre realmente nunca alguien vez cuenta puede\n",
            "Tópico 6: siento tan puedo siempre gente mierda vez cansado hacer triste\n",
            "Tópico 7: quiero siempre siento vida simplemente hacer puedo aquí tan importa\n",
            "Tópico 8: vida siempre alguien nunca odio personas gente noche solo demasiado\n",
            "Tópico 9: vida puedo nadie mierda hacer bien odio día importa siento\n",
            "Tópico 10: alguien nunca tan realmente importa siento quiero vez cómo hablar\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}